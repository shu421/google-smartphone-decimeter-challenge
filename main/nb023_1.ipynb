{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb445c72-a83b-4b89-9f17-b9070fbae63a",
   "metadata": {},
   "source": [
    "# 1. Reject outlier\n",
    "# 2. Kalman filter\n",
    "# 3. Phone mean prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69d3a760-9217-4c90-9e42-26ba35d6d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import simdkalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "05b118cb-1466-4108-92eb-e44cde429504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8684f817-6035-4da6-9e3e-dd157bbc4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trafic(df, center, zoom=9):\n",
    "    fig = px.scatter_mapbox(df,\n",
    "                            \n",
    "                            # Here, plotly gets, (x,y) coordinates\n",
    "                            lat=\"latDeg\",\n",
    "                            lon=\"lngDeg\",\n",
    "                            \n",
    "                            #Here, plotly detects color of series\n",
    "                            color=\"phoneName\",\n",
    "                            labels=\"phoneName\",\n",
    "                            \n",
    "                            zoom=zoom,\n",
    "                            center=center,\n",
    "                            height=600,\n",
    "                            width=800)\n",
    "    fig.update_layout(mapbox_style='stamen-terrain')\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.update_layout(title_text=\"GPS trafic\")\n",
    "    fig.show()\n",
    "    \n",
    "def visualize_collection(df, collection):\n",
    "    target_df = df[df['collectionName']==collection].copy()\n",
    "    lat_center = target_df['latDeg'].mean()\n",
    "    lng_center = target_df['lngDeg'].mean()\n",
    "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
    "    \n",
    "    visualize_trafic(target_df, center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4ecf0c7-38e0-4cfe-8226-24daeac099db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "57d0f674-d165-42e9-85e1-f64a852bd1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "base_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7523b191-0b70-49d7-9e52-a7144996fcd0",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ground_truth.csv count :  73\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/73 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89400ed3331d43648c36ed093e3d704b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "        collectionName phoneName  millisSinceGpsEpoch     latDeg      lngDeg  \\\n0  2020-05-21-US-MTV-1    Pixel4        1274119793431  37.424354 -122.091865   \n1  2020-05-21-US-MTV-1    Pixel4        1274119794431  37.424354 -122.091865   \n2  2020-05-21-US-MTV-1    Pixel4        1274119795431  37.424354 -122.091865   \n3  2020-05-21-US-MTV-1    Pixel4        1274119796431  37.424354 -122.091865   \n4  2020-05-21-US-MTV-1    Pixel4        1274119797431  37.424354 -122.091865   \n\n   heightAboveWgs84EllipsoidM  timeSinceFirstFixSeconds  hDop  vDop  speedMps  \\\n0                       33.89                    461.43   2.9   0.0       0.0   \n1                       33.89                    462.43   2.9   0.0       0.0   \n2                       33.89                    463.43   2.9   0.0       0.0   \n3                       33.89                    464.43   2.9   0.0       0.0   \n4                       33.90                    465.43   2.9   0.0       0.0   \n\n   courseDegree  \n0          76.5  \n1          76.5  \n2          76.5  \n3          76.5  \n4          76.5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>collectionName</th>\n      <th>phoneName</th>\n      <th>millisSinceGpsEpoch</th>\n      <th>latDeg</th>\n      <th>lngDeg</th>\n      <th>heightAboveWgs84EllipsoidM</th>\n      <th>timeSinceFirstFixSeconds</th>\n      <th>hDop</th>\n      <th>vDop</th>\n      <th>speedMps</th>\n      <th>courseDegree</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-05-21-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1274119793431</td>\n      <td>37.424354</td>\n      <td>-122.091865</td>\n      <td>33.89</td>\n      <td>461.43</td>\n      <td>2.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>76.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-05-21-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1274119794431</td>\n      <td>37.424354</td>\n      <td>-122.091865</td>\n      <td>33.89</td>\n      <td>462.43</td>\n      <td>2.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>76.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-05-21-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1274119795431</td>\n      <td>37.424354</td>\n      <td>-122.091865</td>\n      <td>33.89</td>\n      <td>463.43</td>\n      <td>2.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>76.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-05-21-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1274119796431</td>\n      <td>37.424354</td>\n      <td>-122.091865</td>\n      <td>33.89</td>\n      <td>464.43</td>\n      <td>2.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>76.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-05-21-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1274119797431</td>\n      <td>37.424354</td>\n      <td>-122.091865</td>\n      <td>33.90</td>\n      <td>465.43</td>\n      <td>2.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>76.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# ground_truth\n",
    "p = pathlib.Path(INPUT)\n",
    "gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "print('ground_truth.csv count : ', len(gt_files))\n",
    "\n",
    "gts = []\n",
    "for gt_file in tqdm(gt_files):\n",
    "    gts.append(pd.read_csv(gt_file))\n",
    "ground_truth = pd.concat(gts)\n",
    "\n",
    "display(ground_truth.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14476743-00af-458f-986d-c8c03e58831d",
   "metadata": {},
   "source": [
    "## Reject outlier\n",
    "- 前と後の距離がそれぞれ50m以上離れていたら削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a0f488a-4938-4044-9103-7e2313fc1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_diff(df):\n",
    "    df['latDeg_prev'] = df['latDeg'].shift(1)\n",
    "    df['latDeg_next'] = df['latDeg'].shift(-1)\n",
    "    df['lngDeg_prev'] = df['lngDeg'].shift(1)\n",
    "    df['lngDeg_next'] = df['lngDeg'].shift(-1)\n",
    "    df['phone_prev'] = df['phone'].shift(1)\n",
    "    df['phone_next'] = df['phone'].shift(-1)\n",
    "    \n",
    "    df['dist_prev'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_prev'], df['lngDeg_prev'])\n",
    "    df['dist_next'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_next'], df['lngDeg_next'])\n",
    "    \n",
    "    df.loc[df['phone']!=df['phone_prev'], ['latDeg_prev', 'lngDeg_prev', 'dist_prev']] = np.nan\n",
    "    df.loc[df['phone']!=df['phone_next'], ['latDeg_next', 'lngDeg_next', 'dist_next']] = np.nan\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f843ba7-1e6e-46dc-8bb2-28d020f375da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reject outlier\n",
    "train_ro = add_distance_diff(base_train)\n",
    "th = 43\n",
    "train_ro.loc[((train_ro['dist_prev'] > th) | (train_ro['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e3ee3-ee3f-431f-a3a8-131b4b017719",
   "metadata": {},
   "source": [
    "# Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "291d4e9f-1569-4de6-bf2e-bfd412da7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "state_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n",
    "                             [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\n",
    "process_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\n",
    "observation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\n",
    "observation_noise = np.diag([5e-5, 5e-5]) + np.ones((2, 2)) * 1e-9\n",
    "\n",
    "kf = simdkalman.KalmanFilter(\n",
    "        state_transition = state_transition,\n",
    "        process_noise = process_noise,\n",
    "        observation_model = observation_model,\n",
    "        observation_noise = observation_noise)\n",
    "\n",
    "def apply_kf_smoothing(df, kf_=kf):\n",
    "    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n",
    "    for collection, phone in unique_paths:\n",
    "        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n",
    "        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n",
    "        data = data.reshape(1, len(data), 2)\n",
    "        smoothed = kf_.smooth(data)\n",
    "        df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n",
    "        df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59662ff7-c91c-4204-8c65-bb65965691a8",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "cols = ['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']\n",
    "train_ro_kf = apply_kf_smoothing(train_ro[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578b25d-bda9-448e-8a63-ffc1038de6d5",
   "metadata": {},
   "source": [
    "## Phone mean prediction\n",
    "- to use the average of the predictions of several phones in the same collection as the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "97516a1f-57f0-48d8-a259-cbbe6dab4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lerp_data(df):\n",
    "    '''\n",
    "    Generate interpolated lat,lng values for different phone times in the same collection.\n",
    "    '''\n",
    "    org_columns = df.columns\n",
    "    \n",
    "    # Generate a combination of time x collection x phone and combine it with the original data (generate records to be interpolated)\n",
    "    time_list = df[['collectionName', 'millisSinceGpsEpoch']].drop_duplicates()\n",
    "    phone_list =df[['collectionName', 'phoneName']].drop_duplicates()\n",
    "    tmp = time_list.merge(phone_list, on='collectionName', how='outer')\n",
    "    \n",
    "    lerp_df = tmp.merge(df, on=['collectionName', 'millisSinceGpsEpoch', 'phoneName'], how='left')\n",
    "    lerp_df['phone'] = lerp_df['collectionName'] + '_' + lerp_df['phoneName']\n",
    "    lerp_df = lerp_df.sort_values(['phone', 'millisSinceGpsEpoch'])\n",
    "    \n",
    "    # linear interpolation\n",
    "    lerp_df['latDeg_prev'] = lerp_df['latDeg'].shift(1)\n",
    "    lerp_df['latDeg_next'] = lerp_df['latDeg'].shift(-1)\n",
    "    lerp_df['lngDeg_prev'] = lerp_df['lngDeg'].shift(1)\n",
    "    lerp_df['lngDeg_next'] = lerp_df['lngDeg'].shift(-1)\n",
    "    lerp_df['phone_prev'] = lerp_df['phone'].shift(1)\n",
    "    lerp_df['phone_next'] = lerp_df['phone'].shift(-1)\n",
    "    lerp_df['time_prev'] = lerp_df['millisSinceGpsEpoch'].shift(1)\n",
    "    lerp_df['time_next'] = lerp_df['millisSinceGpsEpoch'].shift(-1)\n",
    "    # Leave only records to be interpolated\n",
    "    lerp_df = lerp_df[(lerp_df['latDeg'].isnull())&(lerp_df['phone']==lerp_df['phone_prev'])&(lerp_df['phone']==lerp_df['phone_next'])].copy()\n",
    "    # calc lerp\n",
    "    lerp_df['latDeg'] = lerp_df['latDeg_prev'] + ((lerp_df['latDeg_next'] - lerp_df['latDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n",
    "    lerp_df['lngDeg'] = lerp_df['lngDeg_prev'] + ((lerp_df['lngDeg_next'] - lerp_df['lngDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n",
    "    \n",
    "    # Leave only the data that has a complete set of previous and next data.\n",
    "    lerp_df = lerp_df[~lerp_df['latDeg'].isnull()]\n",
    "    \n",
    "    return lerp_df[org_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b081dca1-d4a7-4939-bdea-750d25d8765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_pred(df, lerp_df):\n",
    "    '''\n",
    "    Make a prediction based on the average of the predictions of phones in the same collection.\n",
    "    '''\n",
    "    add_lerp = pd.concat([df, lerp_df])\n",
    "    mean_pred_result = add_lerp.groupby(['collectionName', 'millisSinceGpsEpoch'])[['latDeg', 'lngDeg']].mean().reset_index()\n",
    "    mean_pred_df = df[['collectionName', 'phoneName', 'millisSinceGpsEpoch']].copy()\n",
    "    mean_pred_df = mean_pred_df.merge(mean_pred_result[['collectionName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']], on=['collectionName', 'millisSinceGpsEpoch'], how='left')\n",
    "    return mean_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa6b2df9-115e-402d-a508-f2ddd2fe7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lerp = make_lerp_data(train_ro_kf)\n",
    "train_mean_pred = calc_mean_pred(train_ro_kf, train_lerp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "100e82e8-ea7c-48fa-a35e-514f7fc702cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = train_ro_kf.copy()\n",
    "tmp2 = train_mean_pred.copy()\n",
    "tmp2['phoneName'] = tmp2['phoneName'] + '_MEAN'\n",
    "tmp3 = ground_truth.copy()\n",
    "tmp3['phoneName'] = tmp3['phoneName'] + '_GT'\n",
    "tmp = pd.concat([tmp1, tmp2, tmp3])\n",
    "# visualize_collection(tmp, '2020-05-14-US-MTV-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8c5e9337-de00-4208-809b-efa98006ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de24cd4e-4610-44e3-b88c-b2fde236ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95]) # phoneによってgroupbyし、gtと予測値の差(err)の50%,95%値を求める\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8226723-bdc1-4bdf-9da9-92e2b3722887",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "kf + reject_outlier :  4.498849117070059\n+ phones_mean_pred :  4.034688363261449\n"
     ]
    }
   ],
   "source": [
    "print('kf + reject_outlier : ', get_train_score(train_ro_kf, ground_truth))\n",
    "print('+ phones_mean_pred : ', get_train_score(train_mean_pred, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6077a50-8370-4092-82b8-ac7f17e013eb",
   "metadata": {},
   "source": [
    "## フィルター済みtrainファイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77485f40-b343-4a42-a116-0ad73f70a8d8",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        phone  millisSinceGpsEpoch     latDeg      lngDeg\n",
       "0  2020-05-14-US-MTV-1_Pixel4        1273529463442  37.423549 -122.094006\n",
       "1  2020-05-14-US-MTV-1_Pixel4        1273529464442  37.423564 -122.094063\n",
       "2  2020-05-14-US-MTV-1_Pixel4        1273529465442  37.423573 -122.094098\n",
       "3  2020-05-14-US-MTV-1_Pixel4        1273529466442  37.423578 -122.094116\n",
       "4  2020-05-14-US-MTV-1_Pixel4        1273529467442  37.423571 -122.094115"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>phone</th>\n      <th>millisSinceGpsEpoch</th>\n      <th>latDeg</th>\n      <th>lngDeg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>1273529463442</td>\n      <td>37.423549</td>\n      <td>-122.094006</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>1273529464442</td>\n      <td>37.423564</td>\n      <td>-122.094063</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>1273529465442</td>\n      <td>37.423573</td>\n      <td>-122.094098</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>1273529466442</td>\n      <td>37.423578</td>\n      <td>-122.094116</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>1273529467442</td>\n      <td>37.423571</td>\n      <td>-122.094115</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "train_mean_pred['phone'] = train_mean_pred['collectionName'] + '_' + train_mean_pred['phoneName']\n",
    "train_mean_pred = train_mean_pred.drop('collectionName', axis=1)\n",
    "train_mean_pred = train_mean_pred.drop('phoneName', axis=1)\n",
    "train_mean_pred = train_mean_pred.reindex(['phone', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg'],\n",
    "                                         axis='columns')\n",
    "train_mean_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e960caff-0683-47b0-832d-d6c4ddd9710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_pred.to_csv('../output/filtered_nb023_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c081e-5ca8-4b74-b7ff-9c40f65a45a4",
   "metadata": {},
   "source": [
    "## submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25c6415c-622c-478a-a7c4-ab3282e231aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test = add_distance_diff(base_test)\n",
    "th = 43\n",
    "base_test.loc[((base_test['dist_prev'] > th) | (base_test['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan\n",
    "\n",
    "test_kf = apply_kf_smoothing(base_test)\n",
    "\n",
    "test_lerp = make_lerp_data(test_kf)\n",
    "test_mean_pred = calc_mean_pred(test_kf, test_lerp)\n",
    "\n",
    "sample_sub['latDeg'] = test_mean_pred['latDeg']\n",
    "sample_sub['lngDeg'] = test_mean_pred['lngDeg']\n",
    "sample_sub.to_csv('../output/sub_nb023_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29519127-2408-4964-aef8-a7f092bf9234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}