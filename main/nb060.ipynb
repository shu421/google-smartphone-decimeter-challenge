{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truth.csv count :  73\n"
     ]
    }
   ],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist\n",
    "\n",
    "    \n",
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)\n",
    "\n",
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    # df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    df = df.merge(gt, on=['phone', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    # df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95]) # phoneによってgroupbyし、gtと予測値の差(err)の50%,95%値を求める\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "# ground_truth\n",
    "p = pathlib.Path(INPUT)\n",
    "gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "print('ground_truth.csv count : ', len(gt_files))\n",
    "\n",
    "gts = []\n",
    "for gt_file in gt_files:\n",
    "    gts.append(pd.read_csv(gt_file))\n",
    "ground_truth = pd.concat(gts)\n",
    "ground_truth['phone'] = ground_truth['collectionName'] + '_' + ground_truth['phoneName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembling(main, support, coeff1, coeff2): \n",
    "    \n",
    "    suba  = main.copy() \n",
    "    subav = suba.values\n",
    "       \n",
    "    subb  = support.copy()\n",
    "    subbv = subb.values    \n",
    "           \n",
    "    ense  = main.copy()    \n",
    "    ensev = ense.values  \n",
    " \n",
    "    for i in range (len(main)):\n",
    "        \n",
    "        pera1 = subav[i, 2]\n",
    "        pera2 = subav[i, 3]\n",
    "        \n",
    "        perb1 = subbv[i, 2]\n",
    "        perb2 = subbv[i, 3]\n",
    "\n",
    "        per1 = (pera1 * coeff1) + (perb1 * (1.0 - coeff1))\n",
    "        per2 = (pera2 * coeff2) + (perb2 * (1.0 - coeff2))\n",
    "        \n",
    "        ensev[i, 2] = per1\n",
    "        ensev[i, 3] = per2\n",
    "        \n",
    "    ense.iloc[:, 2:] = ensev[:, 2:]  \n",
    "  \n",
    "    return ense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3.142271664685327"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1 = '../output/filtered_nb046.csv'\n",
    "tmp1 = pd.read_csv(path1)\n",
    "\n",
    "path2 = '../output/filtered_nb056.csv'\n",
    "tmp2 = pd.read_csv(path2)\n",
    "\n",
    "en1 = ensembling(tmp1, tmp2, 0.02, 0.09)\n",
    "get_train_score(en1, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3.1384583490343028"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en3 = ensembling(en1, en2, 0.2, 0.1)\n",
    "get_train_score(en3, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3.4011460757204977"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path3= '../output/filtered_nb065.csv'\n",
    "tmp3 = pd.read_csv(path3)\n",
    "\n",
    "path4 = '../output/filtered_nb046.csv'\n",
    "tmp4 = pd.read_csv(path4)\n",
    "\n",
    "en4 = ensembling(tmp3, tmp4, 0.5, 0.7)\n",
    "get_train_score(en4, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3.137867005883899"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path3= '../output/filtered_nb065.csv'\n",
    "tmp3 = pd.read_csv(path3)\n",
    "\n",
    "path4 = '../output/filtered_nb056.csv'\n",
    "tmp4 = pd.read_csv(path4)\n",
    "\n",
    "en2 = ensembling(tmp3, tmp4, 0.05, 0.09)\n",
    "get_train_score(en2, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '../output/sub_nb065.csv' \n",
    "sub065= pd.read_csv(path2)\n",
    "\n",
    "path1 = '../output/sub_nb056.csv' \n",
    "sub056 = pd.read_csv(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub1 = ensembling(sub5639, sub6027, 0.25, 0.60)\n",
    "\n",
    "sub2 = ensembling(sub065, sub056, 0.05, 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub1.to_csv(\"submission1.csv\",index=False)\n",
    "sub2.to_csv(\"../output/sub_nb060_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4  ('venv_outdoor': venv)",
   "metadata": {
    "interpreter": {
     "hash": "bd00b75c79969edcf008edd1fd5973862c0c93beffacd004fb7d75ad6fcb357f"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}