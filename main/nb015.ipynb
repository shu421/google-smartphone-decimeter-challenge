{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d3a760-9217-4c90-9e42-26ba35d6d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import simdkalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b118cb-1466-4108-92eb-e44cde429504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7d9f1b-b657-4602-a4a8-1ebccade2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory setting\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d0f674-d165-42e9-85e1-f64a852bd1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "base_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7523b191-0b70-49d7-9e52-a7144996fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truth.csv count :  73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9429fc7a3b634c118f8ad2a3b5400869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collectionName</th>\n",
       "      <th>phoneName</th>\n",
       "      <th>millisSinceGpsEpoch</th>\n",
       "      <th>latDeg</th>\n",
       "      <th>lngDeg</th>\n",
       "      <th>heightAboveWgs84EllipsoidM</th>\n",
       "      <th>timeSinceFirstFixSeconds</th>\n",
       "      <th>hDop</th>\n",
       "      <th>vDop</th>\n",
       "      <th>speedMps</th>\n",
       "      <th>courseDegree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-21-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1274119793431</td>\n",
       "      <td>37.424354</td>\n",
       "      <td>-122.091865</td>\n",
       "      <td>33.89</td>\n",
       "      <td>461.43</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-21-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1274119794431</td>\n",
       "      <td>37.424354</td>\n",
       "      <td>-122.091865</td>\n",
       "      <td>33.89</td>\n",
       "      <td>462.43</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-21-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1274119795431</td>\n",
       "      <td>37.424354</td>\n",
       "      <td>-122.091865</td>\n",
       "      <td>33.89</td>\n",
       "      <td>463.43</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-21-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1274119796431</td>\n",
       "      <td>37.424354</td>\n",
       "      <td>-122.091865</td>\n",
       "      <td>33.89</td>\n",
       "      <td>464.43</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-21-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1274119797431</td>\n",
       "      <td>37.424354</td>\n",
       "      <td>-122.091865</td>\n",
       "      <td>33.90</td>\n",
       "      <td>465.43</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        collectionName phoneName  millisSinceGpsEpoch     latDeg      lngDeg  \\\n",
       "0  2020-05-21-US-MTV-1    Pixel4        1274119793431  37.424354 -122.091865   \n",
       "1  2020-05-21-US-MTV-1    Pixel4        1274119794431  37.424354 -122.091865   \n",
       "2  2020-05-21-US-MTV-1    Pixel4        1274119795431  37.424354 -122.091865   \n",
       "3  2020-05-21-US-MTV-1    Pixel4        1274119796431  37.424354 -122.091865   \n",
       "4  2020-05-21-US-MTV-1    Pixel4        1274119797431  37.424354 -122.091865   \n",
       "\n",
       "   heightAboveWgs84EllipsoidM  timeSinceFirstFixSeconds  hDop  vDop  speedMps  \\\n",
       "0                       33.89                    461.43   2.9   0.0       0.0   \n",
       "1                       33.89                    462.43   2.9   0.0       0.0   \n",
       "2                       33.89                    463.43   2.9   0.0       0.0   \n",
       "3                       33.89                    464.43   2.9   0.0       0.0   \n",
       "4                       33.90                    465.43   2.9   0.0       0.0   \n",
       "\n",
       "   courseDegree  \n",
       "0          76.5  \n",
       "1          76.5  \n",
       "2          76.5  \n",
       "3          76.5  \n",
       "4          76.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ground_truth\n",
    "p = pathlib.Path(INPUT)\n",
    "gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "print('ground_truth.csv count : ', len(gt_files))\n",
    "\n",
    "gts = []\n",
    "for gt_file in tqdm(gt_files):\n",
    "    gts.append(pd.read_csv(gt_file))\n",
    "ground_truth = pd.concat(gts)\n",
    "\n",
    "display(ground_truth.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14476743-00af-458f-986d-c8c03e58831d",
   "metadata": {},
   "source": [
    "## Reject outlier\n",
    "- 前と後の距離がそれぞれ50m以上離れていたら削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0f488a-4938-4044-9103-7e2313fc1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_diff(df):\n",
    "    df['latDeg_prev'] = df['latDeg'].shift(1)\n",
    "    df['latDeg_next'] = df['latDeg'].shift(-1)\n",
    "    df['lngDeg_prev'] = df['lngDeg'].shift(1)\n",
    "    df['lngDeg_next'] = df['lngDeg'].shift(-1)\n",
    "    df['phone_prev'] = df['phone'].shift(1)\n",
    "    df['phone_next'] = df['phone'].shift(-1)\n",
    "    \n",
    "    df['dist_prev'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_prev'], df['lngDeg_prev'])\n",
    "    df['dist_next'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_next'], df['lngDeg_next'])\n",
    "    \n",
    "    df.loc[df['phone']!=df['phone_prev'], ['latDeg_prev', 'lngDeg_prev', 'dist_prev']] = np.nan\n",
    "    df.loc[df['phone']!=df['phone_next'], ['latDeg_next', 'lngDeg_next', 'dist_next']] = np.nan\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a26006-c6af-40cb-873f-0d270f30c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reject outlier\n",
    "train_ro = add_distance_diff(base_train)\n",
    "th = 50\n",
    "train_ro.loc[((train_ro['dist_prev'] > th) & (train_ro['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "291d4e9f-1569-4de6-bf2e-bfd412da7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "state_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n",
    "                             [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\n",
    "process_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\n",
    "observation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\n",
    "observation_noise = np.diag([5e-5, 5e-5]) + np.ones((2, 2)) * 1e-9\n",
    "\n",
    "kf = simdkalman.KalmanFilter(\n",
    "        state_transition = state_transition,\n",
    "        process_noise = process_noise,\n",
    "        observation_model = observation_model,\n",
    "        observation_noise = observation_noise)\n",
    "\n",
    "def apply_kf_smoothing(df, kf_=kf):\n",
    "    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n",
    "    for collection, phone in unique_paths:\n",
    "        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n",
    "        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n",
    "        data = data.reshape(1, len(data), 2)\n",
    "        smoothed = kf_.smooth(data)\n",
    "        df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n",
    "        df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59662ff7-c91c-4204-8c65-bb65965691a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "cols = ['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']\n",
    "train_ro_kf = apply_kf_smoothing(train_ro[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578b25d-bda9-448e-8a63-ffc1038de6d5",
   "metadata": {},
   "source": [
    "## Phone mean prediction\n",
    "- to use the average of the predictions of several phones in the same collection as the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97516a1f-57f0-48d8-a259-cbbe6dab4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lerp_data(df):\n",
    "    '''\n",
    "    Generate interpolated lat,lng values for different phone times in the same collection.\n",
    "    '''\n",
    "    org_columns = df.columns\n",
    "    \n",
    "    # Generate a combination of time x collection x phone and combine it with the original data (generate records to be interpolated)\n",
    "    time_list = df[['collectionName', 'millisSinceGpsEpoch']].drop_duplicates()\n",
    "    phone_list =df[['collectionName', 'phoneName']].drop_duplicates()\n",
    "    tmp = time_list.merge(phone_list, on='collectionName', how='outer')\n",
    "    \n",
    "    lerp_df = tmp.merge(df, on=['collectionName', 'millisSinceGpsEpoch', 'phoneName'], how='left')\n",
    "    lerp_df['phone'] = lerp_df['collectionName'] + '_' + lerp_df['phoneName']\n",
    "    lerp_df = lerp_df.sort_values(['phone', 'millisSinceGpsEpoch'])\n",
    "    \n",
    "    # linear interpolation\n",
    "    lerp_df['latDeg_prev'] = lerp_df['latDeg'].shift(1)\n",
    "    lerp_df['latDeg_next'] = lerp_df['latDeg'].shift(-1)\n",
    "    lerp_df['lngDeg_prev'] = lerp_df['lngDeg'].shift(1)\n",
    "    lerp_df['lngDeg_next'] = lerp_df['lngDeg'].shift(-1)\n",
    "    lerp_df['phone_prev'] = lerp_df['phone'].shift(1)\n",
    "    lerp_df['phone_next'] = lerp_df['phone'].shift(-1)\n",
    "    lerp_df['time_prev'] = lerp_df['millisSinceGpsEpoch'].shift(1)\n",
    "    lerp_df['time_next'] = lerp_df['millisSinceGpsEpoch'].shift(-1)\n",
    "    # Leave only records to be interpolated\n",
    "    lerp_df = lerp_df[(lerp_df['latDeg'].isnull())&(lerp_df['phone']==lerp_df['phone_prev'])&(lerp_df['phone']==lerp_df['phone_next'])].copy()\n",
    "    # calc lerp\n",
    "    lerp_df['latDeg'] = lerp_df['latDeg_prev'] + ((lerp_df['latDeg_next'] - lerp_df['latDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n",
    "    lerp_df['lngDeg'] = lerp_df['lngDeg_prev'] + ((lerp_df['lngDeg_next'] - lerp_df['lngDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n",
    "    \n",
    "    # Leave only the data that has a complete set of previous and next data.\n",
    "    lerp_df = lerp_df[~lerp_df['latDeg'].isnull()]\n",
    "    \n",
    "    return lerp_df[org_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b081dca1-d4a7-4939-bdea-750d25d8765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_pred(df, lerp_df):\n",
    "    '''\n",
    "    Make a prediction based on the average of the predictions of phones in the same collection.\n",
    "    '''\n",
    "    add_lerp = pd.concat([df, lerp_df])\n",
    "    mean_pred_result = add_lerp.groupby(['collectionName', 'millisSinceGpsEpoch'])[['latDeg', 'lngDeg']].mean().reset_index()\n",
    "    mean_pred_df = df[['collectionName', 'phoneName', 'millisSinceGpsEpoch']].copy()\n",
    "    mean_pred_df = mean_pred_df.merge(mean_pred_result[['collectionName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']], on=['collectionName', 'millisSinceGpsEpoch'], how='left')\n",
    "    return mean_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa6b2df9-115e-402d-a508-f2ddd2fe7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lerp = make_lerp_data(train_ro_kf)\n",
    "train_mean_pred = calc_mean_pred(train_ro_kf, train_lerp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b84c41-938b-465c-a948-07890c7a0659",
   "metadata": {},
   "source": [
    "# Interpolate by removing device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9d96572-4f08-432d-a826-a3a143cfc609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removedevice(input_df: pd.DataFrame, device: str) -> pd.DataFrame:\n",
    "    input_df['index'] = input_df.index \n",
    "    input_df = input_df.sort_values('millisSinceGpsEpoch')\n",
    "    input_df.index = input_df['millisSinceGpsEpoch'].values # illisSinceGpsEpochをindexにする\n",
    "\n",
    "    output_df = pd.DataFrame() \n",
    "    for _, subdf in input_df.groupby('collectionName'):\n",
    "\n",
    "        phones = subdf['phoneName'].unique()\n",
    "\n",
    "        # 1つのコレクションにphoneが1種類であるか、対象のデバイスがコレクションに含まれていない時\n",
    "        if (len(phones) == 1) or (not device in phones):\n",
    "            output_df = pd.concat([output_df, subdf])\n",
    "            continue\n",
    "\n",
    "        origin_df = subdf.copy()\n",
    "        \n",
    "        # 対象のデバイスの位置を削除\n",
    "        _index = subdf['phoneName']==device\n",
    "        subdf.loc[_index, 'latDeg'] = np.nan\n",
    "        subdf.loc[_index, 'lngDeg'] = np.nan\n",
    "        \n",
    "        # Nanの周りに値が存在していれば、そのNanを補間\n",
    "        # indexを基準として、線形的に補間していく\n",
    "        subdf = subdf.interpolate(method='index', limit_area='inside')\n",
    "        \n",
    "        # 値が存在しないところは、元の値を使う\n",
    "        _index = subdf['latDeg'].isnull()\n",
    "        subdf.loc[_index, 'latDeg'] = origin_df.loc[_index, 'latDeg'].values\n",
    "        subdf.loc[_index, 'lngDeg'] = origin_df.loc[_index, 'lngDeg'].values\n",
    "\n",
    "        output_df = pd.concat([output_df, subdf])\n",
    "\n",
    "    output_df.index = output_df['index'].values\n",
    "    output_df = output_df.sort_index()\n",
    "\n",
    "    del output_df['index']\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af42908f-8139-4a45-a01f-580dd7022c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_remove = get_removedevice(train_mean_pred, 'SamsungS20Ultra')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f107e-8cdf-4159-a2b4-3cdaff74d349",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c5e9337-de00-4208-809b-efa98006ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de24cd4e-4610-44e3-b88c-b2fde236ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95]) # phoneによってgroupbyし、gtと予測値の差(err)の50%,95%値を求める\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8226723-bdc1-4bdf-9da9-92e2b3722887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kf + reject_outlier :  4.551122113134492\n",
      "+ phones_mean_pred :  4.117064134844469\n",
      "+ remove_device :  3.965311803967154\n"
     ]
    }
   ],
   "source": [
    "print('kf + reject_outlier : ', get_train_score(train_ro_kf, ground_truth))\n",
    "print('+ phones_mean_pred : ', get_train_score(train_mean_pred, ground_truth))\n",
    "print('+ remove_device : ', get_train_score(train_remove, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25c6415c-622c-478a-a7c4-ab3282e231aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test = add_distance_diff(base_test)\n",
    "th = 50\n",
    "base_test.loc[((base_test['dist_prev'] > th) & (base_test['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan\n",
    "\n",
    "test_kf = apply_kf_smoothing(base_test)\n",
    "\n",
    "# remove device\n",
    "test_kf['collectionName'] = test_kf['phone'].map(lambda x: x.split('_')[0])\n",
    "test_kf['phoneName'] = test_kf['phone'].map(lambda x: x.split('_')[1])\n",
    "test_kf = get_removedevice(test_kf, 'SamsungS20Ultra')\n",
    "# test_kf = test_kf.drop(columns=['collectionName', 'phoneName'], axis=1)\n",
    "\n",
    "# phone mean pred\n",
    "test_lerp = make_lerp_data(test_kf)\n",
    "test_mean_pred = calc_mean_pred(test_kf, test_lerp)\n",
    "\n",
    "sample_sub['latDeg'] = test_mean_pred['latDeg']\n",
    "sample_sub['lngDeg'] = test_mean_pred['lngDeg']\n",
    "\n",
    "\n",
    "sample_sub.to_csv('../output/sub_nb015.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b231596-808a-4a39-9cad-43ed3c97222e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
