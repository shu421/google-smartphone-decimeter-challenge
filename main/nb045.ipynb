{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('venv_outdoor': venv)",
   "metadata": {
    "interpreter": {
     "hash": "bd00b75c79969edcf008edd1fd5973862c0c93beffacd004fb7d75ad6fcb357f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist\n",
    "\n",
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)\n",
    "\n",
    "def get_train_score(df, gt):\n",
    "    gt['phone'] = gt['collectionName'] + '_' + gt['phoneName']\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    df = df.merge(gt, on=['phone', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95]) # phoneによってgroupbyし、gtと予測値の差(err)の50%,95%値を求める\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gauss_smoothing(df_, params):\n",
    "    df = df_.copy()\n",
    "    SZ_1 = params['sz_1']\n",
    "    SZ_2 = params['sz_2']\n",
    "    SZ_CRIT = params['sz_crit']    \n",
    "    \n",
    "    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n",
    "    for collection, phone in unique_paths:\n",
    "        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n",
    "        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n",
    "                \n",
    "        lat_g1 = gaussian_filter1d(data[:, 0], np.sqrt(SZ_1))\n",
    "        lon_g1 = gaussian_filter1d(data[:, 1], np.sqrt(SZ_1))\n",
    "        lat_g2 = gaussian_filter1d(data[:, 0], np.sqrt(SZ_2))\n",
    "        lon_g2 = gaussian_filter1d(data[:, 1], np.sqrt(SZ_2))\n",
    "\n",
    "        lat_dif = data[1:,0] - data[:-1,0]\n",
    "        lon_dif = data[1:,1] - data[:-1,1]\n",
    "\n",
    "        lat_crit = np.append(np.abs(gaussian_filter1d(lat_dif, np.sqrt(SZ_CRIT)) / (1e-9 + gaussian_filter1d(np.abs(lat_dif), np.sqrt(SZ_CRIT)))),[0])\n",
    "        lon_crit = np.append(np.abs(gaussian_filter1d(lon_dif, np.sqrt(SZ_CRIT)) / (1e-9 + gaussian_filter1d(np.abs(lon_dif), np.sqrt(SZ_CRIT)))),[0])           \n",
    "            \n",
    "        df.loc[cond, 'latDeg'] = lat_g1 * lat_crit + lat_g2 * (1.0 - lat_crit)\n",
    "        df.loc[cond, 'lngDeg'] = lon_g1 * lon_crit + lon_g2 * (1.0 - lon_crit)    \n",
    "                       \n",
    "    return df\n",
    "def mean_with_other_phones(df_):\n",
    "    df = df_.copy()\n",
    "\n",
    "    collections_list = df[['collectionName']].drop_duplicates().to_numpy()\n",
    "\n",
    "    for collection in collections_list:\n",
    "        phone_list = df[df['collectionName'].to_list() == collection][['phoneName']].drop_duplicates().to_numpy()\n",
    "\n",
    "        phone_data = {}\n",
    "        corrections = {}\n",
    "        for phone in phone_list:\n",
    "            cond = np.logical_and(df['collectionName'] == collection[0], df['phoneName'] == phone[0]).to_list()\n",
    "            phone_data[phone[0]] = df[cond][['millisSinceGpsEpoch', 'latDeg', 'lngDeg']].to_numpy()\n",
    "\n",
    "        for current in phone_data:\n",
    "            correction = np.ones(phone_data[current].shape, dtype=np.float)\n",
    "            correction[:,1:] = phone_data[current][:,1:]\n",
    "            \n",
    "            # Telephones data don't complitely match by time, so - interpolate.\n",
    "            for other in phone_data:\n",
    "                if other == current:\n",
    "                    continue\n",
    "\n",
    "                loc = interp1d(phone_data[other][:,0], \n",
    "                               phone_data[other][:,1:], \n",
    "                               axis=0, \n",
    "                               kind='linear', \n",
    "                               copy=False, \n",
    "                               bounds_error=None, \n",
    "                               fill_value='extrapolate', \n",
    "                               assume_sorted=True)\n",
    "                \n",
    "                start_idx = 0\n",
    "                stop_idx = 0\n",
    "                for idx, val in enumerate(phone_data[current][:,0]):\n",
    "                    if val < phone_data[other][0,0]:\n",
    "                        start_idx = idx\n",
    "                    if val < phone_data[other][-1,0]:\n",
    "                        stop_idx = idx\n",
    "\n",
    "                if stop_idx - start_idx > 0:\n",
    "                    correction[start_idx:stop_idx,0] += 1\n",
    "                    correction[start_idx:stop_idx,1:] += loc(phone_data[current][start_idx:stop_idx,0])                    \n",
    "\n",
    "            correction[:,1] /= correction[:,0]\n",
    "            correction[:,2] /= correction[:,0]\n",
    "            \n",
    "            corrections[current] = correction.copy()\n",
    "        \n",
    "        for phone in phone_list:\n",
    "            cond = np.logical_and(df['collectionName'] == collection[0], df['phoneName'] == phone[0]).to_list()\n",
    "            \n",
    "            df.loc[cond, ['latDeg', 'lngDeg']] = corrections[phone[0]][:,1:]            \n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:42: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "base_train\n",
    "test_base = pd.read_csv('../input/google-smartphone-decimeter-challenge/baseline_locations_test.csv')\n",
    "sub = pd.read_csv('../input/google-smartphone-decimeter-challenge/sample_submission.csv')\n",
    "\n",
    "smoothed_baseline = apply_gauss_smoothing(test_base, {'sz_1' : 0.85, 'sz_2' : 5.65, 'sz_crit' : 1.5})\n",
    "smoothed_baseline = mean_with_other_phones(smoothed_baseline)\n",
    "\n",
    "# sub = sub.assign(latDeg=smoothed_baseline.latDeg, lngDeg=smoothed_baseline.lngDeg)\n",
    "# sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ground_truth.csv count :  73\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "# directory setting\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "\n",
    "# base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "# base_train = pd.read_csv('../output/filtered_nb037.csv')\n",
    "base_train = pd.read_csv('../output/filtered_nb041.csv')\n",
    "base_train['collectionName'] = base_train['phone'].map(lambda x: x.split('_')[0])\n",
    "base_train['phoneName'] = base_train['phone'].map(lambda x: x.split('_')[1])\n",
    "\n",
    "# base_test = pd.read_csv('../output/sub_nb037.csv')\n",
    "base_test = pd.read_csv('../output/sub_nb037_5.csv')\n",
    "# base_test = pd.read_csv('../output/fixed_base_test.csv')\n",
    "\n",
    "sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')\n",
    "\n",
    "# ground_truth\n",
    "p = pathlib.Path(INPUT)\n",
    "gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "print('ground_truth.csv count : ', len(gt_files))\n",
    "\n",
    "gts = []\n",
    "for gt_file in gt_files:\n",
    "    gts.append(pd.read_csv(gt_file))\n",
    "ground_truth = pd.concat(gts)\n",
    "ground_truth['phone'] = ground_truth['collectionName'] + '_' + ground_truth['phoneName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.8035925918757334"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "get_train_score(base_train, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.9062696173443814"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "smoothed_baseline = apply_gauss_smoothing(base_train, {'sz_1' : 0.85, 'sz_2' : 5.65, 'sz_crit' : 1.5})\n",
    "get_train_score(smoothed_baseline, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:42: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.5874074412848453"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "smoothed_baseline1 = mean_with_other_phones(smoothed_baseline)\n",
    "get_train_score(smoothed_baseline1, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:42: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.4515872201655102"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "train = mean_with_other_phones(base_train)\n",
    "get_train_score(train, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        phone  millisSinceGpsEpoch     latDeg      lngDeg  \\\n",
       "0  2020-05-14-US-MTV-1_Pixel4        1273529463442  37.423549 -122.094006   \n",
       "1  2020-05-14-US-MTV-1_Pixel4        1273529464442  37.423563 -122.094056   \n",
       "2  2020-05-14-US-MTV-1_Pixel4        1273529465442  37.423571 -122.094090   \n",
       "3  2020-05-14-US-MTV-1_Pixel4        1273529466442  37.423568 -122.094091   \n",
       "4  2020-05-14-US-MTV-1_Pixel4        1273529467442  37.423571 -122.094106   \n",
       "\n",
       "        collectionName phoneName  \n",
       "0  2020-05-14-US-MTV-1    Pixel4  \n",
       "1  2020-05-14-US-MTV-1    Pixel4  \n",
       "2  2020-05-14-US-MTV-1    Pixel4  \n",
       "3  2020-05-14-US-MTV-1    Pixel4  \n",
       "4  2020-05-14-US-MTV-1    Pixel4  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>phone</th>\n      <th>millisSinceGpsEpoch</th>\n      <th>latDeg</th>\n      <th>lngDeg</th>\n      <th>collectionName</th>\n      <th>phoneName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>1273529463442</td>\n      <td>37.423549</td>\n      <td>-122.094006</td>\n      <td>2020-05-14-US-MTV-1</td>\n      <td>Pixel4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>1273529464442</td>\n      <td>37.423563</td>\n      <td>-122.094056</td>\n      <td>2020-05-14-US-MTV-1</td>\n      <td>Pixel4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>1273529465442</td>\n      <td>37.423571</td>\n      <td>-122.094090</td>\n      <td>2020-05-14-US-MTV-1</td>\n      <td>Pixel4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>1273529466442</td>\n      <td>37.423568</td>\n      <td>-122.094091</td>\n      <td>2020-05-14-US-MTV-1</td>\n      <td>Pixel4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-05-14-US-MTV-1_Pixel4</td>\n      <td>1273529467442</td>\n      <td>37.423571</td>\n      <td>-122.094106</td>\n      <td>2020-05-14-US-MTV-1</td>\n      <td>Pixel4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}