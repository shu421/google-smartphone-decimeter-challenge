{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(71)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import simdkalman\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from pathlib import Path\n",
    "import pyproj\n",
    "from pyproj import Proj, transform # 地理的な位置を示す情報を扱うときに、座標系・測地系変換を行ったり、2点間の距離・方位角を計算したりできる。\n",
    "\n",
    "import optuna\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "\n",
    "import gc\n",
    "import optuna\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import osmnx as ox\n",
    "import momepy\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist\n",
    "\n",
    "    \n",
    "def percentile50(x):\n",
    "    return np.percentile(x, 50)\n",
    "def percentile95(x):\n",
    "    return np.percentile(x, 95)\n",
    "\n",
    "def get_train_score(df, gt):\n",
    "    gt = gt.rename(columns={'latDeg':'latDeg_gt', 'lngDeg':'lngDeg_gt'})\n",
    "    # df = df.merge(gt, on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner')\n",
    "    df = df.merge(gt, on=['phone', 'millisSinceGpsEpoch'], how='inner')\n",
    "    # calc_distance_error\n",
    "    df['err'] = calc_haversine(df['latDeg_gt'], df['lngDeg_gt'], df['latDeg'], df['lngDeg'])\n",
    "    # calc_evaluate_score\n",
    "    # df['phone'] = df['collectionName'] + '_' + df['phoneName']\n",
    "    res = df.groupby('phone')['err'].agg([percentile50, percentile95]) # phoneによってgroupbyし、gtと予測値の差(err)の50%,95%値を求める\n",
    "    res['p50_p90_mean'] = (res['percentile50'] + res['percentile95']) / 2 \n",
    "    score = res['p50_p90_mean'].mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truth.csv count :  73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe3646e28b24cb190309d710c3912a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/73 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# directory setting\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "\n",
    "# base_train = pd.read_csv(INPUT + '/' + 'baseline_locations_train.csv')\n",
    "train_df = pd.read_csv('../output/filtered_nb037.csv')\n",
    "train_df['collectionName'] = train_df['phone'].map(lambda x: x.split('_')[0])\n",
    "train_df['phoneName'] = train_df['phone'].map(lambda x: x.split('_')[1])\n",
    "\n",
    "# base_test = pd.read_csv('../output/sub_nb037.csv')\n",
    "test_df = pd.read_csv('../output/sub_nb037.csv')\n",
    "# base_test = pd.read_csv('../output/fixed_base_test.csv')\n",
    "\n",
    "sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')\n",
    "\n",
    "# ground_truth\n",
    "p = pathlib.Path(INPUT)\n",
    "gt_files = list(p.glob('train/*/*/ground_truth.csv'))\n",
    "print('ground_truth.csv count : ', len(gt_files))\n",
    "\n",
    "gts = []\n",
    "for gt_file in tqdm(gt_files):\n",
    "    gts.append(pd.read_csv(gt_file))\n",
    "ground_truth = pd.concat(gts)\n",
    "ground_truth['phone'] = ground_truth['collectionName'] + '_' + ground_truth['phoneName']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reject outlier\n",
    "- 前と後の距離がそれぞれ50m以上離れていたら削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_diff(df):\n",
    "    df['latDeg_prev'] = df['latDeg'].shift(1)\n",
    "    df['latDeg_next'] = df['latDeg'].shift(-1)\n",
    "    df['lngDeg_prev'] = df['lngDeg'].shift(1)\n",
    "    df['lngDeg_next'] = df['lngDeg'].shift(-1)\n",
    "    df['phone_prev'] = df['phone'].shift(1)\n",
    "    df['phone_next'] = df['phone'].shift(-1)\n",
    "    \n",
    "    df['dist_prev'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_prev'], df['lngDeg_prev'])\n",
    "    df['dist_next'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_next'], df['lngDeg_next'])\n",
    "    \n",
    "    df.loc[df['phone']!=df['phone_prev'], ['latDeg_prev', 'lngDeg_prev', 'dist_prev']] = np.nan\n",
    "    df.loc[df['phone']!=df['phone_next'], ['latDeg_next', 'lngDeg_next', 'dist_next']] = np.nan\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "state_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n",
    "                             [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\n",
    "process_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\n",
    "observation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\n",
    "observation_noise = np.diag([5e-5, 5e-5]) + np.ones((2, 2)) * 1e-9\n",
    "\n",
    "kf = simdkalman.KalmanFilter(\n",
    "        state_transition = state_transition,\n",
    "        process_noise = process_noise,\n",
    "        observation_model = observation_model,\n",
    "        observation_noise = observation_noise)\n",
    "\n",
    "def apply_kf_smoothing(df_, kf_=kf):\n",
    "    df = df_.copy()\n",
    "    unique_paths = df[['collectionName', 'phoneName']].drop_duplicates().to_numpy()\n",
    "    for collection, phone in unique_paths:\n",
    "        cond = np.logical_and(df['collectionName'] == collection, df['phoneName'] == phone)\n",
    "        data = df[cond][['latDeg', 'lngDeg']].to_numpy()\n",
    "        data = data.reshape(1, len(data), 2)\n",
    "        smoothed = kf_.smooth(data)\n",
    "        df.loc[cond, 'latDeg'] = smoothed.states.mean[0, :, 0]\n",
    "        df.loc[cond, 'lngDeg'] = smoothed.states.mean[0, :, 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phone mean prediction\n",
    "- to use the average of the predictions of several phones in the same collection as the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lerp_data(df):\n",
    "    '''\n",
    "    Generate interpolated lat,lng values for different phone times in the same collection.\n",
    "    '''\n",
    "    org_columns = df.columns\n",
    "    \n",
    "    # Generate a combination of time x collection x phone and combine it with the original data (generate records to be interpolated)\n",
    "    time_list = df[['collectionName', 'millisSinceGpsEpoch']].drop_duplicates()\n",
    "    phone_list =df[['collectionName', 'phoneName']].drop_duplicates()\n",
    "    tmp = time_list.merge(phone_list, on='collectionName', how='outer')\n",
    "    \n",
    "    lerp_df = tmp.merge(df, on=['collectionName', 'millisSinceGpsEpoch', 'phoneName'], how='left')\n",
    "    lerp_df['phone'] = lerp_df['collectionName'] + '_' + lerp_df['phoneName']\n",
    "    lerp_df = lerp_df.sort_values(['phone', 'millisSinceGpsEpoch'])\n",
    "    \n",
    "    # linear interpolation\n",
    "    lerp_df['latDeg_prev'] = lerp_df['latDeg'].shift(1)\n",
    "    lerp_df['latDeg_next'] = lerp_df['latDeg'].shift(-1)\n",
    "    lerp_df['lngDeg_prev'] = lerp_df['lngDeg'].shift(1)\n",
    "    lerp_df['lngDeg_next'] = lerp_df['lngDeg'].shift(-1)\n",
    "    lerp_df['phone_prev'] = lerp_df['phone'].shift(1)\n",
    "    lerp_df['phone_next'] = lerp_df['phone'].shift(-1)\n",
    "    lerp_df['time_prev'] = lerp_df['millisSinceGpsEpoch'].shift(1)\n",
    "    lerp_df['time_next'] = lerp_df['millisSinceGpsEpoch'].shift(-1)\n",
    "    # Leave only records to be interpolated\n",
    "    lerp_df = lerp_df[(lerp_df['latDeg'].isnull())&(lerp_df['phone']==lerp_df['phone_prev'])&(lerp_df['phone']==lerp_df['phone_next'])].copy()\n",
    "    # calc lerp\n",
    "    lerp_df['latDeg'] = lerp_df['latDeg_prev'] + ((lerp_df['latDeg_next'] - lerp_df['latDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n",
    "    lerp_df['lngDeg'] = lerp_df['lngDeg_prev'] + ((lerp_df['lngDeg_next'] - lerp_df['lngDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n",
    "    \n",
    "    # Leave only the data that has a complete set of previous and next data.\n",
    "    lerp_df = lerp_df[~lerp_df['latDeg'].isnull()]\n",
    "    \n",
    "    return lerp_df[org_columns]\n",
    "\n",
    "\n",
    "def calc_mean_pred(df, lerp_df):\n",
    "    '''\n",
    "    Make a prediction based on the average of the predictions of phones in the same collection.\n",
    "    '''\n",
    "    add_lerp = pd.concat([df, lerp_df])\n",
    "    mean_pred_result = add_lerp.groupby(['collectionName', 'millisSinceGpsEpoch'])[['latDeg', 'lngDeg']].mean().reset_index()\n",
    "    mean_pred_df = df[['collectionName', 'phoneName', 'millisSinceGpsEpoch']].copy()\n",
    "    mean_pred_df = mean_pred_df.merge(mean_pred_result[['collectionName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']], on=['collectionName', 'millisSinceGpsEpoch'], how='left')\n",
    "    return mean_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(71)\n",
    "\n",
    "def get_removedevice(input_df: pd.DataFrame, device: str) -> pd.DataFrame:\n",
    "    input_df['index'] = input_df.index \n",
    "    input_df = input_df.sort_values('millisSinceGpsEpoch')\n",
    "    input_df.index = input_df['millisSinceGpsEpoch'].values # illisSinceGpsEpochをindexにする\n",
    "\n",
    "    output_df = pd.DataFrame() \n",
    "    for _, subdf in input_df.groupby('collectionName'):\n",
    "\n",
    "        phones = subdf['phoneName'].unique()\n",
    "\n",
    "        # 1つのコレクションにphoneが1種類であるか、対象のデバイスがコレクションに含まれていない時\n",
    "        if (len(phones) == 1) or (not device in phones):\n",
    "            output_df = pd.concat([output_df, subdf])\n",
    "            continue\n",
    "\n",
    "        origin_df = subdf.copy()\n",
    "        \n",
    "        # 対象のデバイスの位置を削除\n",
    "        _index = subdf['phoneName']==device\n",
    "        subdf.loc[_index, 'latDeg'] = np.nan\n",
    "        subdf.loc[_index, 'lngDeg'] = np.nan\n",
    "        \n",
    "        # Nanの周りに値が存在していれば、そのNanを補間\n",
    "        # indexを基準として、線形的に補間していく\n",
    "        subdf = subdf.interpolate(method='index', limit_area='inside')\n",
    "        \n",
    "        # 値が存在しないところは、元の値を使う\n",
    "        _index = subdf['latDeg'].isnull()\n",
    "        subdf.loc[_index, 'latDeg'] = origin_df.loc[_index, 'latDeg'].values\n",
    "        subdf.loc[_index, 'lngDeg'] = origin_df.loc[_index, 'lngDeg'].values\n",
    "\n",
    "        output_df = pd.concat([output_df, subdf])\n",
    "\n",
    "    output_df.index = output_df['index'].values\n",
    "    output_df = output_df.sort_index()\n",
    "\n",
    "    del output_df['index']\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(oof, gt=ground_truth):\n",
    "    df = oof.merge(gt, on = ['phone', 'millisSinceGpsEpoch'])\n",
    "    dst_oof = calc_haversine(df.latDeg_x, df.lngDeg_x, df.latDeg_y, df.lngDeg_y)\n",
    "    scores = pd.DataFrame({'phone': df.phone, 'dst': dst_oof})\n",
    "    scores_grp = scores.groupby('phone') # phoneごとに距離誤差を算出\n",
    "    d50 = scores_grp.quantile(.50).reset_index()\n",
    "    d50.columns = ['phone','q50']\n",
    "    d95 = scores_grp.quantile(.95).reset_index()\n",
    "    d95.columns = ['phone', 'q95']\n",
    "    return (scores_grp.quantile(.50).mean() + scores_grp.quantile(.95).mean())/2, d50.merge(d95)\n",
    "\n",
    "def WGS84_to_ECEF(lat, lon, alt):\n",
    "    # convert to randians\n",
    "    rad_lat = lat * (np.pi / 180.0)\n",
    "    rad_lon = lon * (np.pi / 180.0)\n",
    "    a = 6378137.0 # 地球の長半径\n",
    "    # f is the flattening factor\n",
    "    finv = 298.257223563\n",
    "    f = 1 / finv\n",
    "    e2 = 1 - (1 - f) * (1 - f)\n",
    "    # N is the radius of curvature in the prime vertical\n",
    "    N = a / np.sqrt(1 - e2 * np.sin(rad_lat) * np.sin(rad_lat))\n",
    "    x = (N + alt) * np.cos(rad_lat) * np.cos(rad_lon)\n",
    "    y = (N + alt) * np.cos(rad_lat) * np.sin(rad_lon)\n",
    "    z = (N * (1 - e2) + alt)        * np.sin(rad_lat)\n",
    "    return x, y, z\n",
    "\n",
    "transformer = pyproj.Transformer.from_crs(\n",
    "    {\"proj\":\"geocent\", \"ellps\":\"WGS84\", \"datum\":\"WGS84\"},\n",
    "    {\"proj\":'latlong', \"ellps\":'WGS84', \"datum\":'WGS84'})\n",
    "\n",
    "\n",
    "\n",
    "def ECEF_to_WGS84(x,y,z):\n",
    "    lon, lat, alt = transformer.transform(x,y,z,radians=False)\n",
    "    return lon, lat, alt\n",
    "\n",
    "\n",
    "def position_shift(fname, a):\n",
    "    \n",
    "    d = fname\n",
    "    d['heightAboveWgs84EllipsoidM'] = 63.5\n",
    "    d['x'], d['y'], d['z'] = zip(*d.apply(lambda x: WGS84_to_ECEF(x.latDeg, x.lngDeg, x.heightAboveWgs84EllipsoidM), axis=1))\n",
    "    \n",
    "    # a = -0.2\n",
    "    d.sort_values(['phone', 'millisSinceGpsEpoch'], inplace=True)\n",
    "    for fi in ['x','y','z']:\n",
    "        # 1つ下のphoneが同じところで\n",
    "        d[[fi+'p']] = d[fi].shift(1).where(d['phone'].eq(d['phone'].shift(1)))\n",
    "        # diff: 次の地点との差\n",
    "        d[[fi+'diff']] = d[fi] - d[fi+'p']\n",
    "    # dist: 次の地点との距離\n",
    "    d[['dist']] = np.sqrt(d['xdiff']**2 + d['ydiff']**2 + d['zdiff']**2)\n",
    "    for fi in ['x','y','z']:\n",
    "        d[[fi+'new']] = d[fi+'p'] + d[fi+'diff']*(1-a/d['dist'])\n",
    "    lng, lat, alt = ECEF_to_WGS84(d['xnew'].values, d['ynew'].values, d['znew'].values)\n",
    "    \n",
    "    \n",
    "    lng[np.isnan(lng)] = d.loc[np.isnan(lng),'lngDeg']\n",
    "    lat[np.isnan(lat)] = d.loc[np.isnan(lat),'latDeg']\n",
    "    d['latDeg'] = lat\n",
    "    d['lngDeg'] = lng\n",
    "    \n",
    "    d.sort_values(['phone','millisSinceGpsEpoch'], inplace=True)\n",
    "\n",
    "    return d[['phone', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']]\n",
    "\n",
    "def objective(trial):\n",
    "    a = trial.suggest_uniform('a', -1, 1)\n",
    "    score, scores = compute_dist(position_shift(filtered, a), ground_truth)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove low Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_nogt_diff(df):\n",
    "    # shift(1): 上のやつが1個下に下がる → 前のデータ\n",
    "    # shift(-1): 下のやつが1個上に上がる → 次のデータ\n",
    "    df['latDeg_prev'] = df['latDeg'].shift(1)\n",
    "    df['latDeg_next'] = df['latDeg'].shift(-1)\n",
    "    df['lngDeg_prev'] = df['lngDeg'].shift(1)\n",
    "    df['lngDeg_next'] = df['lngDeg'].shift(-1)\n",
    "    df['phone_prev'] = df['phone'].shift(1)\n",
    "    df['phone_next'] = df['phone'].shift(-1)\n",
    "    \n",
    "    df['latDeg_prev_diff'] = df['latDeg'] - df['latDeg_prev']\n",
    "    df['latDeg_next_diff'] = df['latDeg_next'] - df['latDeg']\n",
    "    \n",
    "    df['lngDeg_prev_diff'] = df['lngDeg'] - df['lngDeg_prev']\n",
    "    df['lngDeg_next_diff'] = df['lngDeg_next'] - df['lngDeg']\n",
    "\n",
    "    \n",
    "    df['dist_prev'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_prev'], df['lngDeg_prev'])\n",
    "    df['dist_next'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_next'], df['lngDeg_next'])\n",
    "    \n",
    "    \n",
    "    df.loc[df['phone']!=df['phone_prev'], ['latDeg_prev', 'lngDeg_prev', 'dist_prev', \n",
    "                                          'latDeg_prev_diff', 'lngDeg_prev_diff']] = np.nan\n",
    "    \n",
    "    df.loc[df['phone']!=df['phone_next'], ['latDeg_next', 'lngDeg_next', 'dist_next', \n",
    "                                           'latDeg_next_diff', 'lngDeg_next_diff']] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "def remove_lowSpeed(_df, dist_thr=0.4):\n",
    "    df = _df.copy()\n",
    "    df['latDeg'] = df['latDeg'].astype(float)\n",
    "    df['lngDeg'] = df['lngDeg'].astype(float)\n",
    "\n",
    "    df = add_distance_nogt_diff(df)\n",
    "\n",
    "    _index = df[(df['dist_prev']<dist_thr) | (df['dist_next']<dist_thr)]['latDeg'].index\n",
    "    df.loc[_index, 'latDeg'] = np.nan\n",
    "    df.loc[_index, 'lngDeg'] = np.nan\n",
    "    # phoneごとに補間する\n",
    "    dfs = []\n",
    "    for _, df in df.groupby('phone'):\n",
    "        df = df.interpolate(method='linear',\n",
    "                            limit=None,\n",
    "                            limit_direction='both')\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    return df[['phone','millisSinceGpsEpoch','latDeg','lngDeg']]\n",
    "\n",
    "\n",
    "def objective_rmls(trial):\n",
    "    x = trial.suggest_uniform('x', 0.5, 0.9)\n",
    "    score = get_train_score(remove_lowSpeed(filtered, x), ground_truth)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective_rmls, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phones mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_with_other_phones(df_):\n",
    "    df = df_.copy()\n",
    "\n",
    "    collections_list = df[['collectionName']].drop_duplicates().to_numpy()\n",
    "\n",
    "    for collection in collections_list:\n",
    "        phone_list = df[df['collectionName'].to_list() == collection][['phoneName']].drop_duplicates().to_numpy()\n",
    "\n",
    "        phone_data = {}\n",
    "        corrections = {}\n",
    "        for phone in phone_list:\n",
    "            cond = np.logical_and(df['collectionName'] == collection[0], df['phoneName'] == phone[0]).to_list()\n",
    "            phone_data[phone[0]] = df[cond][['millisSinceGpsEpoch', 'latDeg', 'lngDeg']].to_numpy()\n",
    "\n",
    "        for current in phone_data:\n",
    "            correction = np.ones(phone_data[current].shape, dtype=np.float64)\n",
    "            correction[:,1:] = phone_data[current][:,1:]\n",
    "            \n",
    "            # Telephones data don't complitely match by time, so - interpolate.\n",
    "            for other in phone_data:\n",
    "                if other == current:\n",
    "                    continue\n",
    "\n",
    "                loc = interp1d(phone_data[other][:,0], \n",
    "                               phone_data[other][:,1:], \n",
    "                               axis=0, \n",
    "                               kind='linear', \n",
    "                               copy=False, \n",
    "                               bounds_error=None, \n",
    "                               fill_value='extrapolate', \n",
    "                               assume_sorted=True)\n",
    "                \n",
    "                start_idx = 0\n",
    "                stop_idx = 0\n",
    "                for idx, val in enumerate(phone_data[current][:,0]):\n",
    "                    if val < phone_data[other][0,0]:\n",
    "                        start_idx = idx\n",
    "                    if val < phone_data[other][-1,0]:\n",
    "                        stop_idx = idx\n",
    "\n",
    "                if stop_idx - start_idx > 0:\n",
    "                    correction[start_idx:stop_idx,0] += 1\n",
    "                    correction[start_idx:stop_idx,1:] += loc(phone_data[current][start_idx:stop_idx,0])                    \n",
    "\n",
    "            correction[:,1] /= correction[:,0]\n",
    "            correction[:,2] /= correction[:,0]\n",
    "            \n",
    "            corrections[current] = correction.copy()\n",
    "        \n",
    "        for phone in phone_list:\n",
    "            cond = np.logical_and(df['collectionName'] == collection[0], df['phoneName'] == phone[0]).to_list()\n",
    "            \n",
    "            df.loc[cond, ['latDeg', 'lngDeg']] = corrections[phone[0]][:,1:]            \n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# snap to grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_to_grid(df_, target_collection):\n",
    "    df = df_.copy()\n",
    "    target_gt_df = ground_truth[ground_truth[\"collectionName\"]==target_collection].reset_index(drop=True)\n",
    "    # for scoring\n",
    "    target_gt_df['phone'] = target_gt_df['collectionName'] + '_' + target_gt_df['phoneName']\n",
    "\n",
    "    df_target_collection = df[df['collectionName']==target_collection]\n",
    "\n",
    "    # change pd.DataFrame -> gpd.GeoDataFrame\n",
    "    # target_gt_df[\"geometry\"] = [Point(p) for p in target_gt_df[[\"lngDeg\", \"latDeg\"]].to_numpy()]\n",
    "    # target_gt_gpd = gpd.GeoDataFrame(target_gt_df, geometry=target_gt_df[\"geometry\"])\n",
    "\n",
    "    df_target_collection[\"geometry\"] = [Point(p) for p in df_target_collection[[\"lngDeg\", \"latDeg\"]].to_numpy()]\n",
    "    target_gpd = gpd.GeoDataFrame(df_target_collection, geometry=df_target_collection[\"geometry\"])\n",
    "\n",
    "    # get road data from open street map by osmnx\n",
    "    offset = 0.1**5\n",
    "    bbox = target_gpd.bounds + [-offset, -offset, offset, offset]\n",
    "    east = bbox[\"minx\"].min()\n",
    "    west = bbox[\"maxx\"].max()\n",
    "    south = bbox[\"miny\"].min()\n",
    "    north = bbox[\"maxy\"].max()\n",
    "    G = ox.graph.graph_from_bbox(north, south, east, west, network_type='drive')\n",
    "\n",
    "\n",
    "    nodes, edges = momepy.nx_to_gdf(G)\n",
    "\n",
    "\n",
    "    edges = edges.dropna(subset=[\"geometry\"]).reset_index(drop=True)\n",
    "    hits = bbox.apply(lambda row: list(edges.sindex.intersection(row)), axis=1)\n",
    "    tmp = pd.DataFrame({\n",
    "        # index of points table\n",
    "        \"pt_idx\": np.repeat(hits.index, hits.apply(len)),\n",
    "        # ordinal position of line - access via iloc later\n",
    "        \"line_i\": np.concatenate(hits.values)\n",
    "    })\n",
    "    # Join back to the lines on line_i; we use reset_index() to \n",
    "    # give us the ordinal position of each line\n",
    "    tmp = tmp.join(edges.reset_index(drop=True), on=\"line_i\")\n",
    "    # Join back to the original points to get their geometry\n",
    "    # rename the point geometry as \"point\"\n",
    "    tmp = tmp.join(target_gpd.geometry.rename(\"point\"), on=\"pt_idx\")\n",
    "    # Convert back to a GeoDataFrame, so we can do spatial ops\n",
    "    tmp = gpd.GeoDataFrame(tmp, geometry=\"geometry\", crs=target_gpd.crs)\n",
    "\n",
    "\n",
    "    tmp[\"snap_dist\"] = tmp.geometry.distance(gpd.GeoSeries(tmp.point))\n",
    "\n",
    "    # Discard any lines that are greater than tolerance from points\n",
    "    tolerance = 0.0005  \n",
    "    tmp = tmp.loc[tmp.snap_dist <= tolerance]\n",
    "    # Sort on ascending snap distance, so that closest goes to top\n",
    "    tmp = tmp.sort_values(by=[\"snap_dist\"])\n",
    "\n",
    "    # group by the index of the points and take the first, which is the\n",
    "    # closest line \n",
    "    closest = tmp.groupby(\"pt_idx\").first()\n",
    "    # construct a GeoDataFrame of the closest lines\n",
    "    closest = gpd.GeoDataFrame(closest, geometry=\"geometry\")\n",
    "    closest = closest.drop_duplicates(\"line_i\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "    line_points_list = []\n",
    "    split = 50  # param: number of split in each LineString\n",
    "    for dist in range(0, split, 1):\n",
    "        dist = dist/split\n",
    "        line_points = closest[\"geometry\"].interpolate(dist, normalized=True)\n",
    "        line_points_list.append(line_points)\n",
    "    line_points = pd.concat(line_points_list).reset_index(drop=True)\n",
    "    line_points = line_points.reset_index().rename(columns={0:\"geometry\"})\n",
    "    line_points[\"lngDeg\"] = line_points[\"geometry\"].x\n",
    "    line_points[\"latDeg\"] = line_points[\"geometry\"].y\n",
    "    def find_closest_point(point, points, max_thr=19, min_thr=16):\n",
    "        \"\"\" Find closest point from a list of points. \"\"\"\n",
    "        df_ = pd.DataFrame({'latDeg':point['latDeg'].repeat(len(points)), \n",
    "                            'lngDeg':point['lngDeg'].repeat(len(points))},\n",
    "                            columns=['latDeg', 'lngDeg'])\n",
    "        # return minimum distance points\n",
    "        distance = calc_haversine(points['latDeg'], points['lngDeg'],\n",
    "                                    df_['latDeg'], df_['lngDeg']).min()\n",
    "        if min_thr <= distance <= max_thr:\n",
    "            return points.loc[calc_haversine(points['latDeg'], points['lngDeg'],\n",
    "                                df_['latDeg'], df_['lngDeg']).argmin()]\n",
    "\n",
    "\n",
    "    def apply_grid_point(x, closest_point):\n",
    "        '''\n",
    "        input: \n",
    "            x: train row\n",
    "            closest_point: closest point or None\n",
    "        '''\n",
    "        idx = x.name\n",
    "        closest_point1 = closest_point[closest_point.index==idx]\n",
    "        if closest_point1.isnull().values == True:\n",
    "            pass\n",
    "        else:\n",
    "            x['latDeg'] = closest_point1.values[0]['latDeg']\n",
    "            x['lngDeg'] = closest_point1.values[0]['lngDeg']\n",
    "        return x\n",
    "\n",
    "    closest_point = df_target_collection[['latDeg','lngDeg']].apply(lambda x: find_closest_point(x, line_points[['latDeg', 'lngDeg']], max_thr=19, min_thr=17), axis=1)\n",
    "    df_target_collection[['latDeg', 'lngDeg']] = df_target_collection[['latDeg', 'lngDeg']].parallel_apply(apply_grid_point, closest_point=closest_point, axis=1)\n",
    "\n",
    "    df.loc[df['collectionName']==target_collection] = df_target_collection\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reject outlier + kalmanfilter:  4.498849117070059\n",
      "phone mean pred :  4.034688363261449\n",
      "phones mean : 3.5362898482112963\n",
      "remove low speed:  3.486164724134517\n",
      "position shift:  3.4184543506885996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/momepy/utils.py:418: UserWarning: Approach is not set. Defaulting to 'primal'.\n",
      "  warnings.warn(\"Approach is not set. Defaulting to 'primal'.\")\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:4326\n",
      "Right CRS: None\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/momepy/utils.py:418: UserWarning: Approach is not set. Defaulting to 'primal'.\n",
      "  warnings.warn(\"Approach is not set. Defaulting to 'primal'.\")\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:4326\n",
      "Right CRS: None\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/momepy/utils.py:418: UserWarning: Approach is not set. Defaulting to 'primal'.\n",
      "  warnings.warn(\"Approach is not set. Defaulting to 'primal'.\")\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:4326\n",
      "Right CRS: None\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snap to grid:  3.410128837665967\n",
      "ro, kf, pm, rm, psm, rmls, ps:  3.410128837665967\n"
     ]
    }
   ],
   "source": [
    "train = train_df.copy()\n",
    "# reject outlier\n",
    "train_ro = add_distance_diff(train)\n",
    "th = 43\n",
    "train_ro.loc[((train_ro['dist_prev'] > th) | (train_ro['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan\n",
    "\n",
    "# kalman filter\n",
    "cols = ['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']\n",
    "train_ro_kf = apply_kf_smoothing(train_ro[cols])\n",
    "\n",
    "# phone mean pred\n",
    "train_lerp = make_lerp_data(train_ro_kf)\n",
    "train_mean_pred = calc_mean_pred(train_ro_kf, train_lerp)\n",
    "\n",
    "train_ro_kf['phone'] = train_ro_kf['collectionName'] + '_' + train_ro_kf['phoneName']\n",
    "train_mean_pred['phone'] = train_mean_pred['collectionName'] + '_' + train_mean_pred['phoneName']\n",
    "\n",
    "print('reject outlier + kalmanfilter: ', get_train_score(train_ro_kf, ground_truth))\n",
    "print('phone mean pred : ', get_train_score(train_mean_pred, ground_truth))\n",
    "\n",
    "train_mean_pred = train_mean_pred.drop('collectionName', axis=1)\n",
    "train_mean_pred = train_mean_pred.drop('phoneName', axis=1)\n",
    "train_mean_pred = train_mean_pred.reindex(['phone', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg'], axis='columns')\n",
    "filtered = train_mean_pred\n",
    "\n",
    "# remove device\n",
    "filtered['collectionName'] =filtered['phone'].map(lambda x: x.split('_')[0])\n",
    "filtered['phoneName'] = filtered['phone'].map(lambda x: x.split('_')[1])\n",
    "filtered = get_removedevice(filtered, 'SamsungS20Ultra')\n",
    "filtered = filtered.drop(columns=['collectionName', 'phoneName'], axis=1)\n",
    "\n",
    "# phones mean\n",
    "filtered['collectionName'] =filtered['phone'].map(lambda x: x.split('_')[0])\n",
    "filtered['phoneName'] = filtered['phone'].map(lambda x: x.split('_')[1])\n",
    "filtered = mean_with_other_phones(filtered)\n",
    "filtered = filtered.drop(columns=['collectionName', 'phoneName'], axis=1)\n",
    "print('phones mean :', get_train_score(filtered, ground_truth))\n",
    "\n",
    "# remove lowSpeed\n",
    "filtered = remove_lowSpeed(filtered, 0.6939300630849313)\n",
    "print('remove low speed: ', get_train_score(filtered, ground_truth))\n",
    "\n",
    "# position shift\n",
    "filtered = position_shift(filtered, a=0.6602905068929037)\n",
    "print('position shift: ', get_train_score(filtered, ground_truth))\n",
    "\n",
    "# snap to grid\n",
    "collection_uniq = train_df['collectionName'].unique()\n",
    "SJC = [i for i in collection_uniq if 'SJC' in i]\n",
    "filtered['collectionName'] =filtered['phone'].map(lambda x: x.split('_')[0])\n",
    "filtered['phoneName'] = filtered['phone'].map(lambda x: x.split('_')[1])\n",
    "for collection in SJC:\n",
    "    filtered = snap_to_grid(filtered, collection)\n",
    "print('snap to grid: ', get_train_score(filtered, ground_truth))\n",
    "# to csv\n",
    "# filtered.to_csv('../output/filtered_nb046.csv', index=False)\n",
    "\n",
    "# score\n",
    "print('ro, kf, pm, rm, psm, rmls, ps: ', get_train_score(filtered, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/momepy/utils.py:418: UserWarning: Approach is not set. Defaulting to 'primal'.\n",
      "  warnings.warn(\"Approach is not set. Defaulting to 'primal'.\")\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:4326\n",
      "Right CRS: None\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/momepy/utils.py:418: UserWarning: Approach is not set. Defaulting to 'primal'.\n",
      "  warnings.warn(\"Approach is not set. Defaulting to 'primal'.\")\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:4326\n",
      "Right CRS: None\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/momepy/utils.py:418: UserWarning: Approach is not set. Defaulting to 'primal'.\n",
      "  warnings.warn(\"Approach is not set. Defaulting to 'primal'.\")\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:4326\n",
      "Right CRS: None\n",
      "\n",
      "/Users/shugo/Desktop/Competitions/kaggle/outdoor/venv_outdoor/lib/python3.7/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "# subfileの雛形\n",
    "submission = sample_sub\n",
    "\n",
    "# reject outlier\n",
    "test_ro = add_distance_diff(test_df)\n",
    "th = 43\n",
    "test_ro.loc[((test_ro['dist_prev'] > th) | (test_ro['dist_next'] > th)), ['latDeg', 'lngDeg']] = np.nan\n",
    "\n",
    "# kalman filter\n",
    "test_kf = apply_kf_smoothing(test_ro)\n",
    "\n",
    "# phone mean pred\n",
    "test_lerp = make_lerp_data(test_kf)\n",
    "test_mean_pred = calc_mean_pred(test_kf, test_lerp)\n",
    "submission['latDeg'] = test_mean_pred['latDeg']\n",
    "submission['lngDeg'] = test_mean_pred['lngDeg']\n",
    "\n",
    "# Remove Device\n",
    "submission['collectionName'] = submission['phone'].map(lambda x: x.split('_')[0])\n",
    "submission['phoneName'] = submission['phone'].map(lambda x: x.split('_')[1])\n",
    "submission = get_removedevice(submission, 'SamsungS20Ultra')\n",
    "submission = submission.drop(columns=['collectionName', 'phoneName'], axis=1)\n",
    "\n",
    "# phones mean\n",
    "submission['collectionName'] =submission['phone'].map(lambda x: x.split('_')[0])\n",
    "submission['phoneName'] = submission['phone'].map(lambda x: x.split('_')[1])\n",
    "submission = mean_with_other_phones(submission)\n",
    "submission = submission.drop(columns=['collectionName', 'phoneName'], axis=1)\n",
    "\n",
    "# remove lowSpeed\n",
    "submission = remove_lowSpeed(submission, 0.6939300630849313)\n",
    "\n",
    "# position shift\n",
    "submission = position_shift(submission, a=0.6602905068929037)\n",
    "\n",
    "# snap to grid\n",
    "collection_uniq = test_df['collectionName'].unique()\n",
    "SJC = [i for i in collection_uniq if 'SJC' in i]\n",
    "submission['collectionName'] =submission['phone'].map(lambda x: x.split('_')[0])\n",
    "submission['phoneName'] = submission['phone'].map(lambda x: x.split('_')[1])\n",
    "for collection in SJC:\n",
    "    submission = snap_to_grid(submission, collection)\n",
    "submission = submission.drop(columns=['collectionName', 'phoneName'], axis=1)\n",
    "\n",
    "# submission\n",
    "submission.to_csv('../output/sub_nb053.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4  ('venv_outdoor': venv)",
   "metadata": {
    "interpreter": {
     "hash": "bd00b75c79969edcf008edd1fd5973862c0c93beffacd004fb7d75ad6fcb357f"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}