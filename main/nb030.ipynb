{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('venv_outdoor': venv)",
   "metadata": {
    "interpreter": {
     "hash": "bd00b75c79969edcf008edd1fd5973862c0c93beffacd004fb7d75ad6fcb357f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "import scipy.optimize as opt\n",
    "\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "INPUT = Path(\"../input/google-smartphone-decimeter-challenge/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecef2lla(x, y, z):\n",
    "    # x, y and z are scalars or vectors in meters\n",
    "    x = np.array([x]).reshape(np.array([x]).shape[-1], 1)\n",
    "    y = np.array([y]).reshape(np.array([y]).shape[-1], 1)\n",
    "    z = np.array([z]).reshape(np.array([z]).shape[-1], 1)\n",
    "\n",
    "    a=6378137\n",
    "    a_sq=a**2\n",
    "    e = 8.181919084261345e-2\n",
    "    e_sq = 6.69437999014e-3\n",
    "\n",
    "    f = 1/298.257223563\n",
    "    b = a*(1-f)\n",
    "\n",
    "    # calculations:\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    ep_sq  = (a**2-b**2)/b**2\n",
    "    ee = (a**2-b**2)\n",
    "    f = (54*b**2)*(z**2)\n",
    "    g = r**2 + (1 - e_sq)*(z**2) - e_sq*ee*2\n",
    "    c = (e_sq**2)*f*r**2/(g**3)\n",
    "    s = (1 + c + np.sqrt(c**2 + 2*c))**(1/3.)\n",
    "    p = f/(3.*(g**2)*(s + (1./s) + 1)**2)\n",
    "    q = np.sqrt(1 + 2*p*e_sq**2)\n",
    "    r_0 = -(p*e_sq*r)/(1+q) + np.sqrt(0.5*(a**2)*(1+(1./q)) - p*(z**2)*(1-e_sq)/(q*(1+q)) - 0.5*p*(r**2))\n",
    "    u = np.sqrt((r - e_sq*r_0)**2 + z**2)\n",
    "    v = np.sqrt((r - e_sq*r_0)**2 + (1 - e_sq)*z**2)\n",
    "    z_0 = (b**2)*z/(a*v)\n",
    "    h = u*(1 - b**2/(a*v))\n",
    "    phi = np.arctan((z + ep_sq*z_0)/r)\n",
    "    lambd = np.arctan2(y, x)\n",
    "\n",
    "    return phi*180/np.pi, lambd*180/np.pi, h\n",
    "\n",
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "      np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "source": [
    "# Apply WLS on one collection and one measurement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test_derived.csv count : 48\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/48 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b746c3637c544f49d5095cfba98a248"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# directory setting\n",
    "INPUT = '../input/google-smartphone-decimeter-challenge'\n",
    "p = pathlib.Path(INPUT)\n",
    "\n",
    "base_test = pd.read_csv(INPUT + '/' + 'baseline_locations_test.csv')\n",
    "sample_sub = pd.read_csv(INPUT + '/' + 'sample_submission.csv')\n",
    "\n",
    "# test derived\n",
    "test_files = list(p.glob('test/*/*/*_derived.csv'))\n",
    "print('test_derived.csv count :', len(test_files))\n",
    "\n",
    "tds = []\n",
    "for test_file in tqdm(test_files):\n",
    "    tds.append(pd.read_csv(test_file))\n",
    "test_derived = pd.concat(tds)\n",
    "test_derived['phone'] = test_derived['collectionName'] + '_' + test_derived['phoneName']\n",
    "\n",
    "\n",
    "collection_name = [i for i in base_test['phone'].unique()]\n",
    "phone = [i for i in base_test['phoneName'].unique()]\n",
    "\n",
    "# base_testに含まれているmillisSinceGpsEpochを使う\n",
    "test_derived = test_derived[test_derived['millisSinceGpsEpoch'].isin(base_test['millisSinceGpsEpoch'])]\n",
    "# derivedのサンプルが少ないと、最適化がうまくできないので、20以上のものだけを使う\n",
    "valid_index = test_derived['millisSinceGpsEpoch'].value_counts()[test_derived['millisSinceGpsEpoch'].value_counts()>20].index\n",
    "test_derived = test_derived[test_derived['millisSinceGpsEpoch'].isin(valid_index)]\n",
    "\n",
    "\n",
    "# Corrected pseudorange according to data instructions\n",
    "test_derived['correctedPrM'] = test_derived.apply(\n",
    "    lambda r: r.rawPrM + r.satClkBiasM - r.isrbM - r.ionoDelayM - r.tropoDelayM,\n",
    "    axis=1\n",
    ").copy()\n",
    "\n",
    "# Time it took for signal to travel\n",
    "light_speed = 299_792_458\n",
    "test_derived['transmissionTimeSeconds'] = (test_derived['correctedPrM'] / light_speed).copy()\n",
    "\n",
    "\n",
    "# Compute true sat positions at arrival time\n",
    "omega_e = 7.2921151467e-5\n",
    "test_derived['xSatPosMRotated'] = \\\n",
    "    np.cos(omega_e * test_derived['transmissionTimeSeconds']) * test_derived['xSatPosM'] \\\n",
    "    + np.sin(omega_e * test_derived['transmissionTimeSeconds']) * test_derived['ySatPosM']\n",
    "    \n",
    "test_derived['ySatPosMRotated'] = \\\n",
    "    - np.sin(omega_e * test_derived['transmissionTimeSeconds']) * test_derived['xSatPosM'] \\\n",
    "    + np.cos(omega_e * test_derived['transmissionTimeSeconds']) * test_derived['ySatPosM']\n",
    "    \n",
    "test_derived['zSatPosMRotated'] = test_derived['zSatPosM']\n",
    "\n",
    "\n",
    "# Uncertainty weight for the WLS method\n",
    "test_derived['uncertaintyWeight'] = 1 / test_derived['rawPrUncM']\n",
    "\n",
    "\n",
    "def apply_wls_pos(df):\n",
    "    '''\n",
    "    input: millisSinceGpsEpochごとのデータフレーム\n",
    "    output: 修正済みlat, lng\n",
    "    '''\n",
    "    \n",
    "    def distance(sat_pos, x):\n",
    "        '''\n",
    "        input: millisSinceGpsEpochごとにまとめられたデータフレーム\n",
    "        output: 入力されたデータフレームの行数と同じ大きさのベクトル\n",
    "        '''\n",
    "        sat_pos_diff = sat_pos.copy(deep=True)\n",
    "        sat_pos_diff['xSatPosMRotated'] = sat_pos_diff['xSatPosMRotated'] - x[0]\n",
    "        sat_pos_diff['ySatPosMRotated'] = sat_pos_diff['ySatPosMRotated'] - x[1]\n",
    "        sat_pos_diff['zSatPosMRotated'] = sat_pos_diff['zSatPosMRotated'] - x[2]\n",
    "\n",
    "        sat_pos_diff['d'] = sat_pos_diff.apply(\n",
    "            lambda r: r.uncertaintyWeight * \n",
    "                (np.sqrt((r.xSatPosMRotated**2 + r.ySatPosMRotated**2 + r.zSatPosMRotated**2)) + x[3] - r.correctedPrM),\n",
    "            axis=1\n",
    "        )\n",
    "        return sat_pos_diff['d'].values\n",
    "\n",
    "    def distance_fixed_satpos(x):\n",
    "        return distance(df[['xSatPosMRotated', 'ySatPosMRotated', 'zSatPosMRotated', 'correctedPrM', 'uncertaintyWeight']], x)\n",
    "\n",
    "\n",
    "    # Start point for the optimiser\n",
    "    x0= [0,0,0,0]\n",
    "\n",
    "    opt_res = opt.least_squares(distance_fixed_satpos, x0)\n",
    "\n",
    "    # Optimiser yields a position in the ECEF coordinates\n",
    "    opt_res_pos = opt_res.x\n",
    "\n",
    "    # ECEF position to lat/long\n",
    "    wls_estimated_pos = ecef2lla(*opt_res_pos[:3]) # x,y,z\n",
    "    wls_estimated_pos = np.squeeze(wls_estimated_pos) # １次元を削除\n",
    "    \n",
    "    \n",
    "    return [wls_estimated_pos[0], wls_estimated_pos[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "CPU times: user 18 s, sys: 3.68 s, total: 21.7 s\n",
      "Wall time: 1h 50min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pandarallel.initialize(use_memory_fs=False)\n",
    "result = test_derived.groupby('millisSinceGpsEpoch').parallel_apply(apply_wls_pos)"
   ]
  },
  {
   "source": [
    "## 整形"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        collectionName phoneName  millisSinceGpsEpoch     latDeg      lngDeg  \\\n",
       "0  2020-05-15-US-MTV-1    Pixel4        1273608785432  37.416628 -122.082053   \n",
       "1  2020-05-15-US-MTV-1    Pixel4        1273608786432  37.416646 -122.082040   \n",
       "2  2020-05-15-US-MTV-1    Pixel4        1273608787432  37.416652 -122.082039   \n",
       "3  2020-05-15-US-MTV-1    Pixel4        1273608788432  37.416607 -122.082063   \n",
       "4  2020-05-15-US-MTV-1    Pixel4        1273608789432  37.416609 -122.082073   \n",
       "\n",
       "   heightAboveWgs84EllipsoidM                       phone  \n",
       "0                      -30.69  2020-05-15-US-MTV-1_Pixel4  \n",
       "1                      -31.76  2020-05-15-US-MTV-1_Pixel4  \n",
       "2                      -31.65  2020-05-15-US-MTV-1_Pixel4  \n",
       "3                      -31.52  2020-05-15-US-MTV-1_Pixel4  \n",
       "4                      -28.95  2020-05-15-US-MTV-1_Pixel4  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>collectionName</th>\n      <th>phoneName</th>\n      <th>millisSinceGpsEpoch</th>\n      <th>latDeg</th>\n      <th>lngDeg</th>\n      <th>heightAboveWgs84EllipsoidM</th>\n      <th>phone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-05-15-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1273608785432</td>\n      <td>37.416628</td>\n      <td>-122.082053</td>\n      <td>-30.69</td>\n      <td>2020-05-15-US-MTV-1_Pixel4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-05-15-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1273608786432</td>\n      <td>37.416646</td>\n      <td>-122.082040</td>\n      <td>-31.76</td>\n      <td>2020-05-15-US-MTV-1_Pixel4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-05-15-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1273608787432</td>\n      <td>37.416652</td>\n      <td>-122.082039</td>\n      <td>-31.65</td>\n      <td>2020-05-15-US-MTV-1_Pixel4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-05-15-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1273608788432</td>\n      <td>37.416607</td>\n      <td>-122.082063</td>\n      <td>-31.52</td>\n      <td>2020-05-15-US-MTV-1_Pixel4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-05-15-US-MTV-1</td>\n      <td>Pixel4</td>\n      <td>1273608789432</td>\n      <td>37.416609</td>\n      <td>-122.082073</td>\n      <td>-28.95</td>\n      <td>2020-05-15-US-MTV-1_Pixel4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# 修正済みlatDeg, lngDegを取り出す\n",
    "fixed_lat = []\n",
    "fixed_lng = []\n",
    "for i in result.values:\n",
    "    fixed_lat.append(i[0])\n",
    "    fixed_lng.append(i[1])\n",
    "result_df = pd.DataFrame({'fixed_latDeg':fixed_lat, 'fixed_lngDeg':fixed_lng}, index=result.index)\n",
    "\n",
    "# 修正済みlatDeg, lngDegをbase_testに適用させる\n",
    "fixed_base_test = pd.merge(base_test, result_df, on='millisSinceGpsEpoch', how='left')\n",
    "fixed_base_test.loc[fixed_base_test['fixed_latDeg'].isnull(), 'fixed_latDeg'] = fixed_base_test['latDeg']\n",
    "fixed_base_test.loc[fixed_base_test['fixed_lngDeg'].isnull(), 'fixed_lngDeg'] = fixed_base_test['lngDeg']\n",
    "fixed_base_test = fixed_base_test.drop(['latDeg', 'lngDeg'], axis=1)\n",
    "fixed_base_test = fixed_base_test.rename(columns={'fixed_latDeg':'latDeg',\n",
    "                                                    'fixed_lngDeg':'lngDeg'})\n",
    "fixed_base_test = fixed_base_test.reindex(columns=['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM', 'phone'])\n",
    "fixed_base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_base_test.to_csv('../output/fixed_base_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}